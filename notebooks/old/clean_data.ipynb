{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94af1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "\n",
    "from lnb_hakatons import PROJECT_DIR\n",
    "\n",
    "# Logging setup\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fd80df",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = PROJECT_DIR / \"data/Mākslu kritika\"\n",
    "\n",
    "KEEP_OTHER_COLUMNS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82c0948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lauki, kurus ņemam ārā\n",
    "columns_to_remove = [\n",
    "    \"UDK (080)\",\n",
    "    \"UDK - 2 (080)\",\n",
    "    \"ILUSTRĀCIJAS (300)\",\n",
    "    \"SATURA VEIDS (336)\",\n",
    "    \"SATURA VEIDS 2 (336)\",\n",
    "    \"BIBLIOGRĀFIJA (504)\"\n",
    "]\n",
    "\n",
    "# Laukus, kurus vajag vienkāršot (expand $$ subfields)\n",
    "key_columns = [\n",
    "    'AUTORS (100)',\n",
    "    'RAKSTA NOSAUKUMS (245)', \n",
    "    'PRIEKŠMETS - TEMATS (650)',\n",
    "    'PRIEKŠMETS - ŽANRS (655)',\n",
    "    'RECENZĒTAIS IZDEVUMS (787)',\n",
    "    'RECENZĒTAIS IZDEVUMS (500)',\n",
    "    \"RECENZĒTĀ FILMA VAI IZRĀDE (630)\",\n",
    "    \"AVOTA NOSAUKUMS (773)\",\n",
    "    \"ELEKTRONISKĀ ADRESE (856)\",\n",
    "    \"PAPILDRAKSTS (700)\",\n",
    "    \"PAPILDRAKSTS - 2 (700)\",\n",
    "    \"NEKONTROLĒTS PERSONAS VĀRDS (720)\",\n",
    "    \"NEKONTROLĒTS PERSONAS VĀRDS - 2 (720)\",\n",
    "    \"NEKONTROLĒTS PERSONAS VĀRDS - 3 (720)\",\n",
    "    \"NEKONTROLĒTS PERSONAS VĀRDS - 4 (720)\",\n",
    "    \"NEKONTROLĒTS PERSONAS VĀRDS - 5 (720)\",\n",
    "    \"PRIEKŠMETS - INSTITŪCIJA (610)\",\n",
    "]\n",
    "\n",
    "# Autoru tipi, kurus analizējam\n",
    "AUTORS_100_4_values = [\"aut\", \"rev\"]\n",
    "\n",
    "literature_categories = [\n",
    "    'Grāmatu apskati',\n",
    "    'Latgaliešu dzeja',\n",
    "    'Latviešu bērnu dzeja',\n",
    "    'Krievu dzeja',\n",
    "    'Latviešu jaunatnes proza',\n",
    "    'Latviešu fantastiskā proza',\n",
    "    'Igauņu dzeja',\n",
    "    'Angļu spiegu romāni',\n",
    "    'Dāņu romāni',\n",
    "    'Amerikāņu fantastiskā proza',\n",
    "    'Zviedru detektīvromāni',\n",
    "    'Čehu romāni',\n",
    "    'Latviešu dienasgrāmatu proza',\n",
    "    'Vācu dzeja',\n",
    "    'Latviešu zinātniskā fantastika',\n",
    "    'Somu dzeja',\n",
    "    'Franču esejas',\n",
    "    'Katalāņu romāni',\n",
    "    'Grieķu dzeja',\n",
    "    'Dienvidafrikāņu romāni (angļu valoda)',\n",
    "    'Čehu stāsti',\n",
    "    'Grieķu romāni',\n",
    "    'Latīņu dzeja',\n",
    "    'Zviedru jaunatnes proza',\n",
    "    'Itāliešu esejas',\n",
    "    'Latviešu skolas proza',\n",
    "    'Krievu detektīvromāni',\n",
    "    'Franču detektīvromāni',\n",
    "    'Austriešu dzeja',\n",
    "    'Čigānu dzeja',\n",
    "    'Spāņu dzeja',\n",
    "    'Armēņu vēsturiskā proza',\n",
    "    'Katoļu himnas un dziesmas',\n",
    "    'Franču dzeja',\n",
    "    'Igauņu romāni',\n",
    "    'Krievu zinātniskā fantastika',\n",
    "    'Mīlas dzeja',\n",
    "    'Bulgāru dzeja',\n",
    "    'Azerbaidžāņu dzeja',\n",
    "    'Zviedru bērnu dzeja',\n",
    "    'Zviedru romāni',\n",
    "    'Poļu fantastiskā proza',\n",
    "    'Holandiešu romāni',\n",
    "    'Latgaliešu bērnu dzeja',\n",
    "    'Krievu Ziemassvētku stāsti',\n",
    "    'Igauņu episkā dzeja',\n",
    "    'Grieķu dzeja, hellēnisma',\n",
    "    'Franču piedzīvojumu proza',\n",
    "    'Krievu bērnu dzeja',\n",
    "    'Čehu dzeja',\n",
    "    'Latviešu romantiskā proza',\n",
    "    'Vācu proza',\n",
    "    'Amerikāņu lugas',\n",
    " ]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa206fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_marc_subfields(text):\n",
    "    \"\"\"\n",
    "    Parse MARC subfields from text containing $$ delimiters.\n",
    "    \n",
    "    Args:\n",
    "        text: String containing MARC subfields with $$ delimiters\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary with subfield codes as keys and content as values\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or text == 'NA':\n",
    "        return {}\n",
    "    \n",
    "    # Pattern to match $$ followed by single character and content\n",
    "    pattern = r'\\$\\$([a-z0-9])([^$]*)'\n",
    "    matches = re.findall(pattern, str(text))\n",
    "    \n",
    "    result = {}\n",
    "    for code, content in matches:\n",
    "        # Clean up content (remove leading/trailing whitespace)\n",
    "        clean_content = content.strip()\n",
    "        if clean_content:\n",
    "            result[code] = clean_content\n",
    "    \n",
    "    return result\n",
    "\n",
    "def expand_marc_columns(df, column_name, prefix=None):\n",
    "    \"\"\"\n",
    "    Expand a MARC column into separate subfield columns.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing MARC data\n",
    "        column_name: Name of the column to expand\n",
    "        prefix: Optional prefix for new column names\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Original DataFrame with new MARC subfield columns\n",
    "    \"\"\"\n",
    "    if prefix is None:\n",
    "        prefix = column_name\n",
    "    \n",
    "    # Parse all MARC subfields in the column\n",
    "    parsed_data = df[column_name].apply(parse_marc_subfields)\n",
    "    \n",
    "    # Collect all unique subfield codes\n",
    "    all_codes = set()\n",
    "    for subfields in parsed_data:\n",
    "        all_codes.update(subfields.keys())\n",
    "    \n",
    "    # Create new columns for each subfield code\n",
    "    for code in sorted(all_codes):\n",
    "        new_col_name = f\"{prefix}_{code}\"\n",
    "        df[new_col_name] = parsed_data.apply(lambda x: x.get(code, None))\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8ea21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_director_from_245(text):\n",
    "    \"\"\"\n",
    "    Extract director name(s) from MARC (245)_b subfield text.\n",
    "    \n",
    "    Looks for patterns like (režisors Name Surname), (rež. Name Surname), etc.\n",
    "    Handles various declensions: režisors, režisore, režisori, režisores, rež.\n",
    "    Supports multiple directors separated by commas.\n",
    "    Handles additional words between director title and name (e.g., \"režisors un scenārists FirstName LastName\").\n",
    "    \n",
    "    Args:\n",
    "        text (str): The text from (245)_b subfield\n",
    "        \n",
    "    Returns:\n",
    "        str or None: Director name(s) if found, None otherwise\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or not text:\n",
    "        return None\n",
    "    \n",
    "    # First, find the opening parenthesis and director title\n",
    "    director_title_pattern = r'\\((?:rež(?:isors?|isore?|isori|isores?|\\.)|режиссёр(?:а|ы|ом|у|е|ов|ям|ями|ях)?|режиссер(?:а|ы|ом|у|е|ов|ям|ями|ях)?)'\n",
    "    \n",
    "    match = re.search(director_title_pattern, text, re.IGNORECASE)\n",
    "    if not match:\n",
    "        return None\n",
    "    \n",
    "    # Get the position after the director title\n",
    "    start_pos = match.end()\n",
    "    \n",
    "    # Find the closing parenthesis\n",
    "    end_pos = text.find(')', start_pos)\n",
    "    if end_pos == -1:\n",
    "        return None\n",
    "    \n",
    "    # Extract everything between the director title and closing parenthesis\n",
    "    directors_text = text[start_pos:end_pos].strip()\n",
    "    \n",
    "    # Clean up: remove any leading words that aren't names (like \"un scenārists\")\n",
    "    # Split by spaces and find the first capitalized word\n",
    "    words = directors_text.split()\n",
    "    name_start_idx = 0\n",
    "    \n",
    "    for i, word in enumerate(words):\n",
    "        # Check if this looks like a name (starts with capital letter)\n",
    "        if word and word[0].isupper():\n",
    "            name_start_idx = i\n",
    "            break\n",
    "    \n",
    "    # Take everything from the first capitalized word to the end\n",
    "    directors_text = ' '.join(words[name_start_idx:])\n",
    "    \n",
    "    if not directors_text:\n",
    "        return None\n",
    "    \n",
    "    # Split by comma and clean up each director name\n",
    "    directors = []\n",
    "    for director in directors_text.split(','):\n",
    "        director = director.strip()\n",
    "        # Clean up the name (remove extra spaces, normalize)\n",
    "        director = re.sub(r'\\s+', ' ', director)\n",
    "        if director:  # Only add non-empty names\n",
    "            directors.append(director)\n",
    "    \n",
    "    directors = \", \".join(directors)\n",
    "    return directors if directors else None\n",
    "\n",
    "\n",
    "def extract_title_from_245(text):\n",
    "    \"\"\"\n",
    "    Extract title from MARC (245)_b subfield text.\n",
    "    \n",
    "    Looks for the first phrase in double quotes, typically after words like \"filma\", \"izrāde\", etc.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The text from (245)_b subfield\n",
    "        \n",
    "    Returns:\n",
    "        str or None: Title if found, None otherwise\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or not text:\n",
    "        return None\n",
    "    \n",
    "    # Pattern to match content in double quotes\n",
    "    # Looks for the first occurrence of text in quotes\n",
    "    title_pattern = r'\"([^\"]+)\"'\n",
    "    \n",
    "    match = re.search(title_pattern, text)\n",
    "    if match:\n",
    "        title = match.group(1).strip()\n",
    "        return title\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_author_from_500(text):\n",
    "    \"\"\"\n",
    "    Extract author from MARC (500)_a field text.\n",
    "    \n",
    "    Looks for author name in curly braces {Surname, Name.} format.\n",
    "    Removes trailing full stop from the name.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The text from (500)_a field\n",
    "        \n",
    "    Returns:\n",
    "        str or None: Author name if found, None otherwise\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or not text:\n",
    "        return None\n",
    "    \n",
    "    # Pattern to match author in curly braces\n",
    "    author_pattern = r'\\{([^}]+)\\}'\n",
    "    \n",
    "    match = re.search(author_pattern, text)\n",
    "    if match:\n",
    "        author = match.group(1).strip()\n",
    "        # Remove trailing full stop if present\n",
    "        author = author.rstrip('.')\n",
    "        # Apply name pattern change (Surname, Name -> Name Surname)\n",
    "        author = change_name_pattern(author)\n",
    "        return author\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_title_from_500(text):\n",
    "    \"\"\"\n",
    "    Extract title from MARC (500)_a field text.\n",
    "    \n",
    "    Looks for title between closing brace } and slash /.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The text from (500)_a field\n",
    "        \n",
    "    Returns:\n",
    "        str or None: Title if found, None otherwise\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or not text:\n",
    "        return None\n",
    "    \n",
    "    # Pattern to match title between } and /\n",
    "    title_pattern = r'\\}\\s*([^/]+?)\\s*/'\n",
    "    \n",
    "    match = re.search(title_pattern, text)\n",
    "    if match:\n",
    "        title = match.group(1).strip()\n",
    "        # Clean up title (remove extra spaces, normalize)\n",
    "        title = re.sub(r'\\s+', ' ', title)\n",
    "        return title\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_publisher_from_500(text):\n",
    "    \"\"\"\n",
    "    Extract publisher from MARC (500)_a field text.\n",
    "    \n",
    "    Looks for publisher between colon after slash and comma.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The text from (500)_a field\n",
    "        \n",
    "    Returns:\n",
    "        str or None: Publisher if found, None otherwise\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or not text:\n",
    "        return None\n",
    "    \n",
    "    # Pattern to match publisher between colon after slash and comma\n",
    "    # First find the slash, then look for colon after it, then capture until comma\n",
    "    publisher_pattern = r'/\\s*[^:]*:\\s*([^,]+)'\n",
    "    \n",
    "    match = re.search(publisher_pattern, text)\n",
    "    if match:\n",
    "        publisher = match.group(1).strip()\n",
    "        # Clean up publisher (remove extra spaces, normalize)\n",
    "        publisher = re.sub(r'\\s+', ' ', publisher)\n",
    "        return publisher\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d305182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_name_pattern(text):\n",
    "    \"\"\"\n",
    "    Change the pattern \"Surname, Name\" to \"Name Surname\"\n",
    "    \n",
    "    Handles various surname patterns including:\n",
    "    - Simple surnames: \"Smith, John\" -> \"John Smith\"\n",
    "    - Hyphenated surnames: \"Lukšo-Ražinska, Elizabete\" -> \"Elizabete Lukšo-Ražinska\"\n",
    "    - Multiple surnames: \"van der Berg, Jan\" -> \"Jan van der Berg\"\n",
    "    - Names with apostrophes: \"O'Connor, Mary\" -> \"Mary O'Connor\"\n",
    "    - Names with periods: \"van der Berg, J.\" -> \"J. van der Berg\"\n",
    "    \n",
    "    Args:\n",
    "        text (str): Name in \"Surname, Name\" format\n",
    "        \n",
    "    Returns:\n",
    "        str: Name in \"Name Surname\" format, or original text if no pattern matches\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or not text:\n",
    "        return text\n",
    "    \n",
    "    # Pattern to match surname (including hyphens, spaces, apostrophes, periods) followed by comma and first name\n",
    "    # [^,]+ matches everything up to the comma (handles complex surnames)\n",
    "    pattern = r'([^,]+),\\s*([^,]+)'\n",
    "    \n",
    "    match = re.search(pattern, text.strip())\n",
    "    if match:\n",
    "        surname = match.group(1).strip()\n",
    "        first_name = match.group(2).strip()\n",
    "        return f\"{first_name} {surname}\"\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286f2646",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = (\n",
    "    pd.read_csv(DATA_DIR / \"cleaned-records-33-wide.csv\", sep=';')\n",
    "    .drop(columns=columns_to_remove, axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd19a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simplified version of the data with expanded MARC columns\n",
    "simplified_df = data_df.copy()\n",
    "\n",
    "for col in key_columns:\n",
    "    if col in simplified_df.columns:\n",
    "        simplified_df = expand_marc_columns(simplified_df, col)\n",
    "\n",
    "# Keep the rest of the columns\n",
    "keep_columns = list(set(data_df.columns).difference(set(key_columns)))\n",
    "\n",
    "# Add all the new MARC subfield columns\n",
    "marc_columns = [col for col in simplified_df.columns if '_' in col]\n",
    "all_columns = keep_columns + marc_columns\n",
    "\n",
    "# Create the simplified dataframe\n",
    "simplified_df = simplified_df[all_columns]\n",
    "\n",
    "print(f\"Original columns: {len(data_df.columns)}\")\n",
    "print(f\"Simplified columns: {len(simplified_df.columns)}\")\n",
    "print(f\"New MARC subfield columns: {len(marc_columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4060c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_uncontrolled_name_columns():\n",
    "    \"\"\"Create sub-field columns for uncontrolled name fields\"\"\"\n",
    "    sub_fields = [\"_4\", \"_a\", \"_c\", \"_d\"]\n",
    "    uncontrolled_name_columns = []\n",
    "    for i in range(1, 6):\n",
    "        if i == 1:\n",
    "            i = \"\"\n",
    "        else:\n",
    "            i = f\" - {i}\"\n",
    "        col_name = f\"NEKONTROLĒTS PERSONAS VĀRDS{i} (720)\"\n",
    "        columns = [col_name + sub_field for sub_field in sub_fields]\n",
    "        uncontrolled_name_columns += columns\n",
    "    return uncontrolled_name_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcc71b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_columns = [\n",
    "    \"AUTORS (100)_4\", # author type; just need rev and aut\n",
    "    \"AUTORS (100)_a\", # author name\n",
    "    \"AUTORS (100)_c\", # additional comment on author; needs to be normalised\n",
    "    \"AUTORS (100)_d\", # date of birth and death; probably needs to be normalised\n",
    "    # extra author\n",
    "    \"PAPILDRAKSTS (700)_4\", # extra author name\n",
    "    \"PAPILDRAKSTS (700)_a\", # extra author\n",
    "    \"PAPILDRAKSTS (700)_c\", # extra author comment\n",
    "    \"PAPILDRAKSTS (700)_d\", # extra author address\n",
    "    # extra author 2\n",
    "    \"PAPILDRAKSTS - 2 (700)_4\", # extra author note\n",
    "    \"PAPILDRAKSTS - 2 (700)_a\", # extra author name\n",
    "    \"PAPILDRAKSTS - 2 (700)_c\", # extra author comment\n",
    "    \"PAPILDRAKSTS - 2 (700)_d\", # extra author address\n",
    "    # title \n",
    "    \"RAKSTA NOSAUKUMS (245)_a\", # title, need to remove trailing colon or dash, also quotation marks\n",
    "    \"RAKSTA NOSAUKUMS (245)_b\", # sub-title, remove square brackets\n",
    "    \"RAKSTA NOSAUKUMS (245)_c\", # author again?\n",
    "    # subject\n",
    "    \"RECENZĒTAIS IZDEVUMS (787)_a\", # reviewed author\n",
    "    \"RECENZĒTAIS IZDEVUMS (787)_t\", # reviewed title\n",
    "    \"RECENZĒTAIS IZDEVUMS (787)_d\", # reviewed publisher\n",
    "    \"RECENZĒTAIS IZDEVUMS (500)_a\", # reviewed title? (all together)   \n",
    "    # filma vai izrāde\n",
    "    \"RECENZĒTĀ FILMA VAI IZRĀDE (630)_a\", # film title\n",
    "    \"RECENZĒTĀ FILMA VAI IZRĀDE (630)_g\", # film type\n",
    "    \"RECENZĒTĀ FILMA VAI IZRĀDE (630)_f\", # year\n",
    "    # source\n",
    "    \"AVOTA NOSAUKUMS (773)_t\", # laikraksts \n",
    "    \"AVOTA NOSAUKUMS (773)_g\", # laikraksta izdevums\n",
    "    # url source\n",
    "    \"ELEKTRONISKĀ ADRESE (856)_u\",\n",
    "    # genre\n",
    "    \"PRIEKŠMETS - TEMATS (650)_a\", # topic\n",
    "    \"PRIEKŠMETS - ŽANRS (655)_a\", # genre\n",
    "    \"PRIEKŠMETS - ŽANRS (655)_x\", # broader genre\n",
    "    # institution\n",
    "    \"PRIEKŠMETS - INSTITŪCIJA (610)_a\", # institution name\n",
    "    \"PRIEKŠMETS - INSTITŪCIJA (610)_g\", # institution type\n",
    "]\n",
    "\n",
    "final_columns += create_uncontrolled_name_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44494a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add rest of the columns\n",
    "if KEEP_OTHER_COLUMNS:\n",
    "    final_columns_all = final_columns + sorted(keep_columns)\n",
    "else:\n",
    "    final_columns_all = final_columns\n",
    "\n",
    "final_columns_all = [col for col in final_columns_all if col in simplified_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b0077c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filtering\n",
    "\n",
    "# Filter by author type\n",
    "logger.info(f\"Original number of rows: {len(data_df)}\")\n",
    "\n",
    "final_df = (\n",
    "    simplified_df.copy()\n",
    "    [final_columns_all]\n",
    "    .loc[simplified_df[\"AUTORS (100)_4\"].isin(AUTORS_100_4_values)]\n",
    ")\n",
    "\n",
    "logger.info(f\"Number of rows after filtering authors: {len(final_df)}\")\n",
    "\n",
    "# Filter only reviews\n",
    "ir_recenzija = final_df[\"PRIEKŠMETS - ŽANRS (655)_a\"].fillna(\"\").str.lower().str.contains(\"recenzija\")\n",
    "ir_gramata = final_df[\"PRIEKŠMETS - ŽANRS (655)_a\"].fillna(\"\").str.lower().str.contains(\"grāmatu apskati\")\n",
    "ir_vesture = final_df[\"PRIEKŠMETS - ŽANRS (655)_x\"].fillna(\"\").str.lower().str.contains(\"vēsture un kritika\")\n",
    "\n",
    "final_df = final_df[ir_recenzija | ir_vesture | ir_gramata]\n",
    "\n",
    "logger.info(f\"Number of rows after filtering recenzijas: {len(final_df)}\")\n",
    "\n",
    "## Processing\n",
    "\n",
    "final_df = (\n",
    "    final_df\n",
    "    .assign(**{\n",
    "        # Change the format of the author from Surname, Name to Name Surname\n",
    "        \"AUTORS (100)_a\": lambda df: df[\"AUTORS (100)_a\"].apply(\n",
    "            lambda val: change_name_pattern(val) if pd.notna(val) and val != \"\" else None\n",
    "        ),\n",
    "        \"PAPILDRAKSTS (700)_a\": lambda df: df[\"PAPILDRAKSTS (700)_a\"].apply(\n",
    "            lambda val: change_name_pattern(val) if pd.notna(val) and val != \"\" else None\n",
    "        ),\n",
    "        \"PAPILDRAKSTS - 2 (700)_a\": lambda df: df[\"PAPILDRAKSTS - 2 (700)_a\"].apply(\n",
    "            lambda val: change_name_pattern(val) if pd.notna(val) and val != \"\" else None\n",
    "        ),\n",
    "        \"NEKONTROLĒTS PERSONAS VĀRDS (720)_a\": lambda df: df[\"NEKONTROLĒTS PERSONAS VĀRDS (720)_a\"].apply(\n",
    "            lambda val: change_name_pattern(val) if pd.notna(val) and val != \"\" else None\n",
    "        ),\n",
    "        \"NEKONTROLĒTS PERSONAS VĀRDS - 2 (720)_a\": lambda df: df[\"NEKONTROLĒTS PERSONAS VĀRDS - 2 (720)_a\"].apply(\n",
    "            lambda val: change_name_pattern(val) if pd.notna(val) and val != \"\" else None\n",
    "        ),\n",
    "        \"NEKONTROLĒTS PERSONAS VĀRDS - 3 (720)_a\": lambda df: df[\"NEKONTROLĒTS PERSONAS VĀRDS - 3 (720)_a\"].apply(\n",
    "            lambda val: change_name_pattern(val) if pd.notna(val) and val != \"\" else None\n",
    "        ),\n",
    "        \"NEKONTROLĒTS PERSONAS VĀRDS - 4 (720)_a\": lambda df: df[\"NEKONTROLĒTS PERSONAS VĀRDS - 4 (720)_a\"].apply(\n",
    "            lambda val: change_name_pattern(val) if pd.notna(val) and val != \"\" else None\n",
    "        ),\n",
    "        \"NEKONTROLĒTS PERSONAS VĀRDS - 5 (720)_a\": lambda df: df[\"NEKONTROLĒTS PERSONAS VĀRDS - 5 (720)_a\"].apply(\n",
    "            lambda val: change_name_pattern(val) if pd.notna(val) and val != \"\" else None\n",
    "        ),\n",
    "        # Combine all authors into one column as a list\n",
    "        \"visas_personas\": lambda df: df[[\"AUTORS (100)_a\", \"PAPILDRAKSTS (700)_a\", \"PAPILDRAKSTS - 2 (700)_a\", \"NEKONTROLĒTS PERSONAS VĀRDS (720)_a\", \"NEKONTROLĒTS PERSONAS VĀRDS - 2 (720)_a\", \"NEKONTROLĒTS PERSONAS VĀRDS - 3 (720)_a\", \"NEKONTROLĒTS PERSONAS VĀRDS - 4 (720)_a\", \"NEKONTROLĒTS PERSONAS VĀRDS - 5 (720)_a\"]].apply(\n",
    "            lambda row: [val for val in row if pd.notna(val) and val != \"\"],\n",
    "            axis=1\n",
    "        ),\n",
    "        # Combine subfields _a and _b\n",
    "        \"RAKSTA NOSAUKUMS (245)_ab\": lambda df: df[\"RAKSTA NOSAUKUMS (245)_a\"] + \" \" + df[\"RAKSTA NOSAUKUMS (245)_b\"],\n",
    "        # Remove full stops in genre\n",
    "        \"PRIEKŠMETS - ŽANRS (655)_a\": lambda df: df[\"PRIEKŠMETS - ŽANRS (655)_a\"].str.replace(\".\", \"\").str.strip(),\n",
    "        \"PRIEKŠMETS - INSTITŪCIJA (610)_a\": lambda df: df[\"PRIEKŠMETS - INSTITŪCIJA (610)_a\"].str.replace(\".\", \"\").str.strip(),        \n",
    "    })\n",
    "    .assign(**{\n",
    "        # remove colon from the end of the title (only the end - there might be a space before and/or after)\n",
    "        \"RAKSTA NOSAUKUMS (245)_a\": lambda df: df[\"RAKSTA NOSAUKUMS (245)_a\"].fillna(\"\").str.rstrip(\": /\").str.strip(),\n",
    "    })\n",
    "    .assign(**{\n",
    "        # Replace only exact matches of \"Latvijas Nacionālā opera\" with \"Latvijas Nacionālā opera un balets\"\n",
    "        \"PRIEKŠMETS - INSTITŪCIJA (610)_a\": lambda df: df[\"PRIEKŠMETS - INSTITŪCIJA (610)_a\"].apply(\n",
    "            lambda val: \"Latvijas Nacionālā opera un balets\" if val == \"Latvijas Nacionālā opera\" else val\n",
    "        )\n",
    "    })\n",
    "    # Extract director and title from (245)_b\n",
    "    .assign(**{\n",
    "        \"(245)_director\": lambda df: df[\"RAKSTA NOSAUKUMS (245)_b\"].apply(\n",
    "            lambda val: extract_director_from_245(val)\n",
    "        ),\n",
    "        \"(245)_title\": lambda df: df[\"RAKSTA NOSAUKUMS (245)_b\"].apply(\n",
    "            lambda val: extract_title_from_245(val)\n",
    "        ),\n",
    "    })\n",
    "    # Extract book author, title, and publisher from (500)_a\n",
    "    .assign(**{\n",
    "        \"(500)_author\": lambda df: df[\"RECENZĒTAIS IZDEVUMS (500)_a\"].apply(\n",
    "            lambda val: extract_author_from_500(val)\n",
    "        ),\n",
    "        \"(500)_title\": lambda df: df[\"RECENZĒTAIS IZDEVUMS (500)_a\"].apply(\n",
    "            lambda val: extract_title_from_500(val)\n",
    "        ),\n",
    "        \"(500)_publisher\": lambda df: df[\"RECENZĒTAIS IZDEVUMS (500)_a\"].apply(\n",
    "            lambda val: extract_publisher_from_500(val)\n",
    "        ),\n",
    "    })\n",
    "    # Book authors\n",
    "    # Populate 787 fields with extracted data (prioritize 787 over 500_a if available)\n",
    "    .assign(**{\n",
    "        \"(787)_author\": lambda df: df[\"RECENZĒTAIS IZDEVUMS (787)_a\"].apply(\n",
    "            lambda val: change_name_pattern(val) if pd.notna(val) and val != \"\" else None\n",
    "        ).fillna(df[\"(500)_author\"]),\n",
    "        \"(787)_title\": lambda df: df[\"RECENZĒTAIS IZDEVUMS (787)_t\"].apply(\n",
    "            lambda val: val if pd.notna(val) and val != \"\" else None\n",
    "        ).fillna(df[\"(500)_title\"]),\n",
    "        \"(787)_publisher\": lambda df: df[\"RECENZĒTAIS IZDEVUMS (787)_d\"].apply(\n",
    "            lambda val: val if pd.notna(val) and val != \"\" else None\n",
    "        ).fillna(df[\"(500)_publisher\"]),\n",
    "    })\n",
    "    # harmonized recenzeta_darba_autors un recenzetais_darbs to combine either 245 or 787\n",
    "    .assign(**{\n",
    "        \"recenzeta_darba_autors\": lambda df: df[\"(787)_author\"].replace(\"\", None).fillna(df[\"(245)_director\"]),\n",
    "        \"recenzetais_darbs\": lambda df: df[\"(787)_title\"].replace(\"\", None).fillna(df[\"(245)_title\"]),\n",
    "        \"publicetajs_vai_institucija\": lambda df: df[\"(787)_publisher\"].replace(\"\", None).fillna(df[\"PRIEKŠMETS - INSTITŪCIJA (610)_a\"]),\n",
    "    })\n",
    "    # fix if there is still a colon in the publicetajs_vai_institucija then take the text between the colon and the next comma\n",
    "    .assign(**{\n",
    "        \"publicetajs_vai_institucija\": lambda df: df[\"publicetajs_vai_institucija\"].apply(\n",
    "            lambda x: x.split(\":\")[1].split(\",\")[0].strip() if pd.notna(x) and \":\" in str(x) else x\n",
    "        ),\n",
    "    })\n",
    "    # try filling rezentais_darbs nulls with RECENZĒTĀ FILMA VAI IZRĀDE (630)_a\n",
    "    .assign(**{\n",
    "        \"recenzetais_darbs\": lambda df: df[\"recenzetais_darbs\"].fillna(df[\"RECENZĒTĀ FILMA VAI IZRĀDE (630)_a\"]),\n",
    "    })\n",
    "    .assign(**{\n",
    "        \"recenzetais_darbs\": lambda df: df[\"recenzetais_darbs\"].str.split(\":\").str[0].str.strip(),\n",
    "    })\n",
    "    # if  PRIEKŠMETS - ŽANRS (655)_a is in literature_categories the use \"Literatūra\", otherwise keep the value\n",
    "    .assign(**{\n",
    "        \"recenzijas_tips\": lambda df: df[\"PRIEKŠMETS - ŽANRS (655)_a\"].apply(\n",
    "            lambda val: \"Literatūras recenzijas\" if val in literature_categories else val\n",
    "        )\n",
    "    })\n",
    "    # drop the helper columns for authors and title, and keep only the harmonised columns\n",
    "    .drop(columns=[\n",
    "        \"(245)_director\",\n",
    "        \"(245)_title\",\n",
    "        \"(500)_author\",\n",
    "        \"(500)_title\",\n",
    "        \"(500)_publisher\",\n",
    "        \"(787)_author\",\n",
    "        \"(787)_title\",\n",
    "        \"(787)_publisher\",\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706ce8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"recenzijas_tips\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d02ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    final_df.sample(10)\n",
    "    [[\n",
    "        \"recenzetais_darbs\",\n",
    "        \"publicetajs_vai_institucija\",\n",
    "        \"recenzijas_tips\",\n",
    "        \n",
    "    ]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a97ec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d62132",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "PRIEKŠMETS - ŽANRS (655)_a\n",
    "327 vienumi ir \"Apskati un recenzijas\" kategorijā \n",
    "\n",
    "PRIEKŠMETS - INSTITŪCIJA (610)_a\n",
    "\"Latvijas Nacionālā opera\" - harmonizēts kā \"Latvijas Nacionālā opera un balets\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
